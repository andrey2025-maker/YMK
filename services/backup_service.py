"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.
–†–µ–∞–ª–∏–∑—É–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π –ë–î, –∞—Ä—Ö–∏–≤–∞—Ü–∏—é –≤ Telegram –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏—è–º–∏.
"""

import os
import json
import logging
import tempfile
import zipfile
import shutil
from typing import Dict, List, Optional, Any, Tuple, BinaryIO
from datetime import datetime, timedelta
from pathlib import Path

import aiofiles
from sqlalchemy import text

from storage.database import async_session_maker
from modules.file.archive_manager import ArchiveManager
from utils.date_utils import format_date

logger = logging.getLogger(__name__)


class BackupType(str, Enum):
    """–¢–∏–ø—ã —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π."""
    FULL = "full"           # –ü–æ–ª–Ω–∞—è –∫–æ–ø–∏—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
    DATABASE = "database"   # –¢–æ–ª—å–∫–æ –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
    FILES = "files"         # –¢–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã
    CONFIG = "config"       # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã


class BackupService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö."""
    
    def __init__(
        self,
        archive_manager: ArchiveManager,
        backup_dir: Optional[str] = None,
        max_backups: int = 30  # –•—Ä–∞–Ω–∏—Ç—å –Ω–µ –±–æ–ª–µ–µ 30 –±—ç–∫–∞–ø–æ–≤
    ):
        self.archive_manager = archive_manager
        self.backup_dir = backup_dir or os.path.join(tempfile.gettempdir(), "bot_backups")
        self.max_backups = max_backups
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –±—ç–∫–∞–ø–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs(self.backup_dir, exist_ok=True)
    
    async def create_full_backup(
        self,
        description: Optional[str] = None,
        send_to_telegram: bool = True
    ) -> Tuple[bool, Optional[str]]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏.
        
        Args:
            description: –û–ø–∏—Å–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞
            send_to_telegram: –û—Ç–ø—Ä–∞–≤–ª—è—Ç—å –ª–∏ –≤ Telegram
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (—É—Å–ø–µ—Ö, –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–ª–∏ None)
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_filename = f"full_backup_{timestamp}.zip"
            backup_path = os.path.join(self.backup_dir, backup_filename)
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –±—ç–∫–∞–ø–∞
            with tempfile.TemporaryDirectory() as temp_dir:
                # 1. –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                db_dump_path = await self._export_database(temp_dir)
                if not db_dump_path:
                    logger.error("Failed to export database")
                    return False, None
                
                # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata_path = await self._save_metadata(temp_dir, description)
                
                # 3. –ö–æ–ø–∏—Ä—É–µ–º –≤–∞–∂–Ω—ã–µ —Ñ–∞–π–ª—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
                await self._copy_important_files(temp_dir)
                
                # 4. –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º –≤—Å—ë –≤ ZIP
                with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for root, dirs, files in os.walk(temp_dir):
                        for file in files:
                            file_path = os.path.join(root, file)
                            arcname = os.path.relpath(file_path, temp_dir)
                            zipf.write(file_path, arcname)
                
                # 5. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if send_to_telegram:
                    await self._send_backup_to_telegram(backup_path, description)
                
                # 6. –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã
                await self._cleanup_old_backups()
                
                logger.info(f"Full backup created: {backup_path}")
                return True, backup_path
                
        except Exception as e:
            logger.error(f"Error creating full backup: {e}")
            return False, None
    
    async def create_database_backup(
        self,
        description: Optional[str] = None,
        send_to_telegram: bool = True
    ) -> Tuple[bool, Optional[str]]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ —Ç–æ–ª—å–∫–æ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            description: –û–ø–∏—Å–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞
            send_to_telegram: –û—Ç–ø—Ä–∞–≤–ª—è—Ç—å –ª–∏ –≤ Telegram
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (—É—Å–ø–µ—Ö, –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–ª–∏ None)
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_filename = f"db_backup_{timestamp}.sql"
            backup_path = os.path.join(self.backup_dir, backup_filename)
            
            # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            async with async_session_maker() as session:
                # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü
                tables = await self._get_database_tables(session)
                
                # –°–æ–∑–¥–∞–µ–º SQL –¥–∞–º–ø
                sql_dump = await self._generate_sql_dump(session, tables)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
                async with aiofiles.open(backup_path, 'w', encoding='utf-8') as f:
                    await f.write(sql_dump)
            
            # –°–∂–∏–º–∞–µ–º —Ñ–∞–π–ª
            compressed_path = f"{backup_path}.gz"
            await self._compress_file(backup_path, compressed_path)
            
            # –£–¥–∞–ª—è–µ–º –Ω–µ—Å–∂–∞—Ç—ã–π —Ñ–∞–π–ª
            os.remove(backup_path)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if send_to_telegram:
                await self._send_backup_to_telegram(compressed_path, description, is_database=True)
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã
            await self._cleanup_old_backups()
            
            logger.info(f"Database backup created: {compressed_path}")
            return True, compressed_path
            
        except Exception as e:
            logger.error(f"Error creating database backup: {e}")
            return False, None
    
    async def restore_from_backup(
        self,
        backup_path: str,
        backup_type: BackupType = BackupType.FULL
    ) -> Tuple[bool, str]:
        """
        –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏.
        
        Args:
            backup_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±—ç–∫–∞–ø–∞
            backup_type: –¢–∏–ø –±—ç–∫–∞–ø–∞
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (—É—Å–ø–µ—Ö, —Å–æ–æ–±—â–µ–Ω–∏–µ)
        """
        try:
            if not os.path.exists(backup_path):
                return False, f"Backup file not found: {backup_path}"
            
            if backup_type == BackupType.DATABASE:
                return await self._restore_database(backup_path)
            elif backup_type == BackupType.FULL:
                return await self._restore_full_backup(backup_path)
            else:
                return False, f"Unsupported backup type: {backup_type}"
                
        except Exception as e:
            logger.error(f"Error restoring from backup: {e}")
            return False, f"Restoration error: {str(e)}"
    
    async def get_backup_list(
        self,
        backup_type: Optional[BackupType] = None,
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π.
        
        Args:
            backup_type: –¢–∏–ø –±—ç–∫–∞–ø–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –±—ç–∫–∞–ø–∞—Ö
        """
        try:
            backups = []
            
            for filename in os.listdir(self.backup_dir):
                filepath = os.path.join(self.backup_dir, filename)
                
                if not os.path.isfile(filepath):
                    continue
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –±—ç–∫–∞–ø–∞ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                file_type = self._get_backup_type_from_filename(filename)
                
                if backup_type and file_type != backup_type:
                    continue
                
                stat = os.stat(filepath)
                size_mb = stat.st_size / (1024 * 1024)
                
                backup_info = {
                    "filename": filename,
                    "filepath": filepath,
                    "type": file_type,
                    "size_mb": round(size_mb, 2),
                    "created_at": datetime.fromtimestamp(stat.st_ctime),
                    "modified_at": datetime.fromtimestamp(stat.st_mtime)
                }
                
                backups.append(backup_info)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
            backups.sort(key=lambda x: x["created_at"], reverse=True)
            
            return backups[:limit]
            
        except Exception as e:
            logger.error(f"Error getting backup list: {e}")
            return []
    
    async def delete_backup(self, filename: str) -> bool:
        """
        –£–¥–∞–ª–µ–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏.
        
        Args:
            filename: –ò–º—è —Ñ–∞–π–ª–∞ –±—ç–∫–∞–ø–∞
            
        Returns:
            True –µ—Å–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            filepath = os.path.join(self.backup_dir, filename)
            
            if not os.path.exists(filepath):
                logger.warning(f"Backup file not found: {filepath}")
                return False
            
            os.remove(filepath)
            logger.info(f"Backup deleted: {filename}")
            return True
            
        except Exception as e:
            logger.error(f"Error deleting backup {filename}: {e}")
            return False
    
    async def backup_health_check(self) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –±—ç–∫–∞–ø–æ–≤
            dir_exists = os.path.exists(self.backup_dir)
            dir_writable = os.access(self.backup_dir, os.W_OK) if dir_exists else False
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –±—ç–∫–∞–ø–æ–≤
            backups = await self.get_backup_list(limit=100)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –±—ç–∫–∞–ø
            last_backup = backups[0] if backups else None
            days_since_last = None
            
            if last_backup:
                days_since_last = (datetime.now() - last_backup["created_at"]).days
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ
            disk_info = await self._get_disk_usage()
            
            health_info = {
                "backup_directory": {
                    "path": self.backup_dir,
                    "exists": dir_exists,
                    "writable": dir_writable
                },
                "backups": {
                    "total_count": len(backups),
                    "types": {
                        "full": len([b for b in backups if b["type"] == BackupType.FULL]),
                        "database": len([b for b in backups if b["type"] == BackupType.DATABASE]),
                        "files": len([b for b in backups if b["type"] == BackupType.FILES])
                    },
                    "total_size_mb": round(sum(b["size_mb"] for b in backups), 2)
                },
                "last_backup": {
                    "filename": last_backup["filename"] if last_backup else None,
                    "age_days": days_since_last,
                    "status": "GOOD" if days_since_last and days_since_last <= 7 else "WARNING"
                } if last_backup else None,
                "disk_space": disk_info,
                "status": "HEALTHY" if dir_exists and dir_writable and backups else "UNHEALTHY"
            }
            
            return health_info
            
        except Exception as e:
            logger.error(f"Error in backup health check: {e}")
            return {"status": "ERROR", "error": str(e)}
    
    async def _export_database(self, temp_dir: str) -> Optional[str]:
        """–≠–∫—Å–ø–æ—Ä—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –≤ SQL —Ñ–∞–π–ª."""
        try:
            dump_path = os.path.join(temp_dir, "database_dump.sql")
            
            async with async_session_maker() as session:
                tables = await self._get_database_tables(session)
                sql_dump = await self._generate_sql_dump(session, tables)
                
                async with aiofiles.open(dump_path, 'w', encoding='utf-8') as f:
                    await f.write(sql_dump)
            
            return dump_path
            
        except Exception as e:
            logger.error(f"Error exporting database: {e}")
            return None
    
    async def _get_database_tables(self, session) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ç–∞–±–ª–∏—Ü –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö."""
        try:
            # PostgreSQL specific query
            query = text("""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_type = 'BASE TABLE'
                ORDER BY table_name
            """)
            
            result = await session.execute(query)
            tables = [row[0] for row in result.fetchall()]
            
            return tables
            
        except Exception as e:
            logger.error(f"Error getting database tables: {e}")
            return []
    
    async def _generate_sql_dump(self, session, tables: List[str]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL –¥–∞–º–ø–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
        sql_lines = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        sql_lines.append(f"-- Database backup created at {timestamp}")
        sql_lines.append(f"-- Tables: {len(tables)}")
        sql_lines.append("")
        
        # –î–ª—è –∫–∞–∂–¥–æ–π —Ç–∞–±–ª–∏—Ü—ã
        for table in tables:
            sql_lines.append(f"-- Table: {table}")
            sql_lines.append(f"DROP TABLE IF EXISTS {table} CASCADE;")
            
            # –ü–æ–ª—É—á–∞–µ–º CREATE TABLE
            create_query = text(f"SELECT pg_get_tabledef('{table}');")
            result = await session.execute(create_query)
            create_sql = result.scalar()
            
            if create_sql:
                sql_lines.append(create_sql + ";")
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            data_query = text(f"SELECT * FROM {table};")
            result = await session.execute(data_query)
            rows = result.fetchall()
            
            if rows:
                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
                columns = result.keys()
                columns_str = ', '.join(columns)
                
                sql_lines.append(f"\n-- Data for table {table}: {len(rows)} rows")
                
                for row in rows:
                    values = []
                    for value in row:
                        if value is None:
                            values.append("NULL")
                        elif isinstance(value, str):
                            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∫–∞–≤—ã—á–∫–∏
                            escaped = value.replace("'", "''")
                            values.append(f"'{escaped}'")
                        elif isinstance(value, datetime):
                            values.append(f"'{value.isoformat()}'")
                        else:
                            values.append(str(value))
                    
                    values_str = ', '.join(values)
                    sql_lines.append(f"INSERT INTO {table} ({columns_str}) VALUES ({values_str});")
            
            sql_lines.append("")
        
        return '\n'.join(sql_lines)
    
    async def _save_metadata(self, temp_dir: str, description: Optional[str]) -> str:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –±—ç–∫–∞–ø–∞."""
        try:
            metadata = {
                "backup_type": "full",
                "created_at": datetime.now().isoformat(),
                "description": description or "Automatic backup",
                "version": "1.0",
                "system_info": {
                    "python_version": os.sys.version,
                    "platform": os.sys.platform
                }
            }
            
            metadata_path = os.path.join(temp_dir, "metadata.json")
            async with aiofiles.open(metadata_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(metadata, indent=2, ensure_ascii=False))
            
            return metadata_path
            
        except Exception as e:
            logger.error(f"Error saving metadata: {e}")
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ñ–∞–π–ª –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å JSON
            metadata_path = os.path.join(temp_dir, "metadata.txt")
            async with aiofiles.open(metadata_path, 'w') as f:
                await f.write(f"Backup created: {datetime.now()}\n")
                await f.write(f"Description: {description or 'N/A'}\n")
            
            return metadata_path
    
    async def _copy_important_files(self, temp_dir: str):
        """–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞–∂–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å–∏—Å—Ç–µ–º—ã."""
        try:
            files_to_backup = []
            
            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            config_files = [".env", "config.py", "docker-compose.yml", "docker-compose.prod.yml"]
            
            for config_file in config_files:
                if os.path.exists(config_file):
                    files_to_backup.append(config_file)
            
            # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
            for filepath in files_to_backup:
                if os.path.exists(filepath):
                    dest_path = os.path.join(temp_dir, "configs", os.path.basename(filepath))
                    os.makedirs(os.path.dirname(dest_path), exist_ok=True)
                    shutil.copy2(filepath, dest_path)
            
        except Exception as e:
            logger.warning(f"Error copying important files: {e}")
    
    async def _send_backup_to_telegram(
        self,
        backup_path: str,
        description: Optional[str] = None,
        is_database: bool = False
    ):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –±—ç–∫–∞–ø–∞ –≤ Telegram."""
        try:
            if not os.path.exists(backup_path):
                logger.warning(f"Backup file not found for Telegram: {backup_path}")
                return
            
            filename = os.path.basename(backup_path)
            file_size_mb = os.path.getsize(backup_path) / (1024 * 1024)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (Telegram –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ ~50MB)
            if file_size_mb > 45:
                logger.warning(f"Backup file too large for Telegram: {file_size_mb:.2f}MB")
                return
            
            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
            async with aiofiles.open(backup_path, 'rb') as f:
                file_data = await f.read()
            
            # –°–æ–∑–¥–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
            backup_type = "Database" if is_database else "Full"
            caption = f"üî∞ {backup_type} Backup\n"
            caption += f"üìÖ {format_date(datetime.now())}\n"
            caption += f"üì¶ {filename}\n"
            caption += f"üìä {file_size_mb:.2f} MB\n"
            
            if description:
                caption += f"üìù {description}\n"
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —á–µ—Ä–µ–∑ ArchiveManager
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã–∑–æ–≤ –º–µ—Ç–æ–¥–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–∞
            # await self.archive_manager.send_backup_file(file_data, filename, caption)
            
            logger.info(f"Backup sent to Telegram: {filename}")
            
        except Exception as e:
            logger.error(f"Error sending backup to Telegram: {e}")
    
    async def _cleanup_old_backups(self):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π."""
        try:
            backups = await self.get_backup_list(limit=1000)  # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ
            
            if len(backups) <= self.max_backups:
                return
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (—Å—Ç–∞—Ä—ã–µ –≤ –∫–æ–Ω—Ü–µ)
            backups.sort(key=lambda x: x["created_at"])
            
            # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ
            to_delete = backups[self.max_backups:]
            
            for backup in to_delete:
                try:
                    os.remove(backup["filepath"])
                    logger.debug(f"Deleted old backup: {backup['filename']}")
                except Exception as e:
                    logger.warning(f"Could not delete backup {backup['filename']}: {e}")
            
            logger.info(f"Cleaned up {len(to_delete)} old backups")
            
        except Exception as e:
            logger.error(f"Error cleaning up old backups: {e}")
    
    def _get_backup_type_from_filename(self, filename: str) -> BackupType:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –±—ç–∫–∞–ø–∞ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞."""
        filename_lower = filename.lower()
        
        if filename_lower.startswith("full_backup"):
            return BackupType.FULL
        elif filename_lower.startswith("db_backup") or ".sql" in filename_lower:
            return BackupType.DATABASE
        elif filename_lower.startswith("config_backup"):
            return BackupType.CONFIG
        elif filename_lower.startswith("files_backup"):
            return BackupType.FILES
        else:
            return BackupType.FULL  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    async def _compress_file(self, source_path: str, dest_path: str):
        """–°–∂–∞—Ç–∏–µ —Ñ–∞–π–ª–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º gzip."""
        try:
            import gzip
            
            async with aiofiles.open(source_path, 'rb') as f_in:
                async with aiofiles.open(dest_path, 'wb') as f_out:
                    # –í –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ –ø—Ä–æ—â–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–∂–∞—Ç–∏–µ
                    # –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
                    data = await f_in.read()
                    compressed = gzip.compress(data)
                    await f_out.write(compressed)
            
        except ImportError:
            # –ï—Å–ª–∏ gzip –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª
            logger.warning("gzip not available, copying file without compression")
            shutil.copy2(source_path, dest_path)
        except Exception as e:
            logger.error(f"Error compressing file: {e}")
            # –ö–æ–ø–∏—Ä—É–µ–º –±–µ–∑ —Å–∂–∞—Ç–∏—è –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            shutil.copy2(source_path, dest_path)
    
    async def _restore_database(self, backup_path: str) -> Tuple[bool, str]:
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏–∑ SQL –¥–∞–º–ø–∞."""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
            if backup_path.endswith('.gz'):
                # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º
                import gzip
                
                temp_path = backup_path.replace('.gz', '')
                with gzip.open(backup_path, 'rt', encoding='utf-8') as f_in:
                    with open(temp_path, 'w', encoding='utf-8') as f_out:
                        f_out.write(f_in.read())
                
                backup_path = temp_path
                cleanup_temp = True
            else:
                cleanup_temp = False
            
            # –ß–∏—Ç–∞–µ–º SQL —Ñ–∞–π–ª
            async with aiofiles.open(backup_path, 'r', encoding='utf-8') as f:
                sql_content = await f.read()
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
            # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ SQL - –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π –º–µ—Ç–æ–¥
            commands = []
            current_command = []
            in_string = False
            string_char = None
            
            for line in sql_content.split('\n'):
                line = line.strip()
                if not line or line.startswith('--'):
                    continue
                
                for char in line:
                    if char in ("'", '"') and (string_char is None or char == string_char):
                        in_string = not in_string
                        string_char = char if in_string else None
                    
                    current_command.append(char)
                
                current_command.append(' ')
                
                if not in_string and line.endswith(';'):
                    command = ''.join(current_command).strip()
                    if command:
                        commands.append(command)
                    current_command = []
            
            # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–∞—Å—å –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞
            if current_command and not in_string:
                command = ''.join(current_command).strip()
                if command and command.endswith(';'):
                    commands.append(command)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–º–∞–Ω–¥—ã
            async with async_session_maker() as session:
                for command in commands:
                    try:
                        await session.execute(text(command))
                    except Exception as e:
                        logger.warning(f"Error executing SQL command: {e}")
                        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥—Ä—É–≥–∏—Ö –∫–æ–º–∞–Ω–¥
            
                await session.commit()
            
            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –µ—Å–ª–∏ –±—ã–ª —Å–æ–∑–¥–∞–Ω
            if cleanup_temp and os.path.exists(backup_path):
                os.remove(backup_path)
            
            return True, f"Database restored successfully from {os.path.basename(backup_path)}"
            
        except Exception as e:
            logger.error(f"Error restoring database: {e}")
            return False, f"Database restoration failed: {str(e)}"
    
    async def _restore_full_backup(self, backup_path: str) -> Tuple[bool, str]:
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ –ø–æ–ª–Ω–æ–π —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏."""
        try:
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏
            with tempfile.TemporaryDirectory() as temp_dir:
                # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º ZIP
                with zipfile.ZipFile(backup_path, 'r') as zipf:
                    zipf.extractall(temp_dir)
                
                # –ò—â–µ–º SQL –¥–∞–º–ø
                sql_dump_path = None
                for root, dirs, files in os.walk(temp_dir):
                    for file in files:
                        if file.endswith('.sql'):
                            sql_dump_path = os.path.join(root, file)
                            break
                
                if not sql_dump_path:
                    return False, "SQL dump not found in backup"
                
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                success, message = await self._restore_database(sql_dump_path)
                
                if not success:
                    return False, f"Failed to restore database: {message}"
                
                # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–æ–≤
                # (–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ —Ç.–¥.)
                
                return True, "Full backup restored successfully"
            
        except Exception as e:
            logger.error(f"Error restoring full backup: {e}")
            return False, f"Full backup restoration failed: {str(e)}"
    
    async def _get_disk_usage(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –¥–∏—Å–∫–∞."""
        try:
            import shutil
            
            total, used, free = shutil.disk_usage(self.backup_dir)
            
            return {
                "total_gb": round(total / (1024**3), 2),
                "used_gb": round(used / (1024**3), 2),
                "free_gb": round(free / (1024**3), 2),
                "free_percent": round((free / total) * 100, 1)
            }
            
        except Exception as e:
            logger.warning(f"Error getting disk usage: {e}")
            return {
                "total_gb": 0,
                "used_gb": 0,
                "free_gb": 0,
                "free_percent": 0
            }
    
    async def auto_backup_if_needed(self, force: bool = False) -> bool:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ.
        
        Args:
            force: –°–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ
            
        Returns:
            True –µ—Å–ª–∏ –±—ç–∫–∞–ø –±—ã–ª —Å–æ–∑–¥–∞–Ω
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–≥–¥–∞ –±—ã–ª –ø–æ—Å–ª–µ–¥–Ω–∏–π –±—ç–∫–∞–ø
            backups = await self.get_backup_list(limit=1)
            
            if backups and not force:
                last_backup = backups[0]
                days_since_last = (datetime.now() - last_backup["created_at"]).days
                
                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –±—ç–∫–∞–ø –±—ã–ª –º–µ–Ω–µ–µ 1 –¥–Ω—è –Ω–∞–∑–∞–¥, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                if days_since_last < 1:
                    logger.debug("Skipping auto-backup: last backup was today")
                    return False
            
            # –°–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø
            description = "Automatic daily backup"
            success, _ = await self.create_database_backup(
                description=description,
                send_to_telegram=False  # –í –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Ä–µ–∂–∏–º–µ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram
            )
            
            if success:
                logger.info("Auto-backup created successfully")
            else:
                logger.warning("Auto-backup creation failed")
            
            return success
            
        except Exception as e:
            logger.error(f"Error in auto-backup: {e}")
            return False